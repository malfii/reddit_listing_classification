{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning and comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will investigate different models and transformers to see which one performs better and what are the best hyperparameters. <br>\n",
    "<br>For estimator, we will use:\n",
    "- Logistic Regression\n",
    "- KNN \n",
    "- Naive Bayes\n",
    "\n",
    "For transformers, the following approaches are used:\n",
    "- `CountVectorizer`\n",
    "- `TfidfVectorizer`\n",
    "\n",
    "Our analysis in starts by using `CountVectorizer` as our initial transformer. Various models will be used on this data and upon finding the best performing model, we will use that model to test against `TfidfVectorizer` as well to see which one performs better. <br>\n",
    "\n",
    "Additionally, we will build a hybrid model in which it uses both the text and word information along with the numerical features extracted from analyzing the text (word count and sentiment data). This is an effort to see whether using extra features or engineered features would help us achieve a better classification performance or not. <br>\n",
    "\n",
    "At the end, we will evaluate the performance of ensemble based decision trees in our classification problem. In this case, we have used `CountVectorizer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import re \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # for sentiment analyzer\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import and train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous section, we will import the data and create train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sometimes I’m like oh wow can’t wait to marry ...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nMy girlfriend is bisexual. While I don’t hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>0.9987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  subreddit  word_count  \\\n",
       "0  Sometimes I’m like oh wow can’t wait to marry ...          0         112   \n",
       "1  \\nMy girlfriend is bisexual. While I don’t hav...          1         620   \n",
       "\n",
       "   sentiment  \n",
       "0     0.8560  \n",
       "1     0.9987  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data from preprocessed data that are saved into files\n",
    "df = pd.read_csv('./../dataset/offmychestrelationship_advice_processed.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text', 'word_count', 'sentiment']]\n",
    "y = df['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y)\n",
    "X_train = pd.DataFrame(X_train, columns=['text', 'word_count', 'sentiment'])\n",
    "X_test = pd.DataFrame(X_test, columns=['text', 'word_count', 'sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we will use the model prepared from benchmarking notebook in which we optimized the Logistic Regression parameters with Gridseach and found the best performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;logr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [3000], &#x27;cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;logr__C&#x27;: [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;logr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [3000], &#x27;cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;logr__C&#x27;: [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()), (&#x27;logr&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('logr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [1.0, 0.8, 0.5],\n",
       "                         'cvec__max_features': [3000], 'cvec__min_df': [2, 4],\n",
       "                         'cvec__ngram_range': [(1, 2)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'logr__C': [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         'logr__penalty': ['l2']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X train and test best on only the text column\n",
    "Z_train = X_train['text']\n",
    "Z_test = X_test['text']\n",
    "# create a pipe instance \n",
    "pipe_cvec_logr = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# decide on what parameters to modify for transformer and estimator\n",
    "params_cvec_logr = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__ngram_range': [(1, 2)],\n",
    "    'cvec__max_df': [1.0, 0.8, 0.5],\n",
    "    'cvec__min_df': [2, 4],\n",
    "    'cvec__max_features': [3000],\n",
    "    'logr__C': [0.02, 0.05, 0.07, 0.1, 0.2],\n",
    "    'logr__penalty': ['l2'], \n",
    "}\n",
    "\n",
    "gs_cvec_logr = GridSearchCV(pipe_cvec_logr,\n",
    "                 param_grid=params_cvec_logr,\n",
    "                 n_jobs=-1,\n",
    "                 cv=3,\n",
    "                 verbose=2)\n",
    "\n",
    "gs_cvec_logr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= LogReg =============\n",
      "best cv score: 0.8803813038130381\n",
      "=============\n",
      "best params:\n",
      "cvec__max_df: 0.5\n",
      "cvec__max_features: 3000\n",
      "cvec__min_df: 2\n",
      "cvec__ngram_range: (1, 2)\n",
      "cvec__stop_words: english\n",
      "logr__C: 0.07\n",
      "logr__penalty: l2\n",
      "=============\n",
      "train score: 0.9491851168511685\n",
      "test score: 0.8834921610820781\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "print('============= LogReg =============')\n",
    "print(f'best cv score: {gs_cvec_logr.best_score_}') # through cross-validation\n",
    "print('=============')\n",
    "print(f'best params:') # best parameters\n",
    "[print(f'{ind}: {val}') for ind, val in gs_cvec_logr.best_params_.items()];\n",
    "print('=============')\n",
    "pred = gs_cvec_logr.predict(Z_test)\n",
    "\n",
    "print(f'train score: {gs_cvec_logr.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs_cvec_logr.score(Z_test, y_test)}')\n",
    "\n",
    "print('=============')\n",
    "#pd.DataFrame(gs_cvec_logr.cv_results_).sort_values(by='mean_test_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will see how KNN will perform in classifying our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan 0.77436962 0.77544588        nan 0.76253075        nan\n",
      "        nan        nan        nan 0.76975707 0.76914207 0.77121771\n",
      " 0.74784748 0.75353629        nan        nan 0.76360701        nan\n",
      " 0.76629766        nan 0.76422202]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;knn&#x27;, KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [0.95],\n",
       "                         &#x27;cvec__max_features&#x27;: [300, 500, 1000],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None],\n",
       "                         &#x27;knn__n_neighbors&#x27;: [8, 10, 12, 14, 16, 18, 20, 22,\n",
       "                                              24]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;knn&#x27;, KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [0.95],\n",
       "                         &#x27;cvec__max_features&#x27;: [300, 500, 1000],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None],\n",
       "                         &#x27;knn__n_neighbors&#x27;: [8, 10, 12, 14, 16, 18, 20, 22,\n",
       "                                              24]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()), (&#x27;knn&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.95],\n",
       "                         'cvec__max_features': [300, 500, 1000],\n",
       "                         'cvec__ngram_range': [(1, 2)],\n",
       "                         'cvec__stop_words': [None],\n",
       "                         'knn__n_neighbors': [8, 10, 12, 14, 16, 18, 20, 22,\n",
       "                                              24]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X train and test best on only the text column\n",
    "Z_train = X_train['text']\n",
    "Z_test = X_test['text']\n",
    "# create a pipe instance \n",
    "pipe_cvec_knn = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# decide on what parameters to modify for transformer and estimator\n",
    "params_cvec_knn = {\n",
    "    'cvec__stop_words': [None] ,# 'english'],\n",
    "    'cvec__ngram_range': [(1, 2)],\n",
    "    'cvec__max_df': [0.95], # 0.8, 0.5],\n",
    "#    'cvec__min_df': [2, 4],\n",
    "    'cvec__max_features': [300, 500, 1000],\n",
    "    'knn__n_neighbors': list(range(8, 25, 2))\n",
    "}\n",
    "\n",
    "gs_cvec_knn = GridSearchCV(pipe_cvec_knn,\n",
    "                 param_grid=params_cvec_knn,\n",
    "                 n_jobs=-1,\n",
    "                 cv=3,\n",
    "                 verbose=1)\n",
    "\n",
    "gs_cvec_knn.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= KNN =============\n",
      "best cv score: 0.7754458794587946\n",
      "=============\n",
      "best params:\n",
      "cvec__max_df: 0.95\n",
      "cvec__max_features: 300\n",
      "cvec__ngram_range: (1, 2)\n",
      "cvec__stop_words: None\n",
      "knn__n_neighbors: 24\n",
      "=============\n",
      "train score: 0.7946648216482165\n",
      "test score: 0.7777436212726714\n",
      "=============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>param_cvec__stop_words</th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.601203</td>\n",
       "      <td>0.481789</td>\n",
       "      <td>22.433740</td>\n",
       "      <td>1.171363</td>\n",
       "      <td>0.95</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 3...</td>\n",
       "      <td>0.770756</td>\n",
       "      <td>0.782518</td>\n",
       "      <td>0.773063</td>\n",
       "      <td>0.775446</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.426651</td>\n",
       "      <td>0.517186</td>\n",
       "      <td>23.454713</td>\n",
       "      <td>1.252792</td>\n",
       "      <td>0.95</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>22</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 3...</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>0.780673</td>\n",
       "      <td>0.773755</td>\n",
       "      <td>0.774370</td>\n",
       "      <td>0.004915</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>35.251082</td>\n",
       "      <td>2.103824</td>\n",
       "      <td>41.037591</td>\n",
       "      <td>1.120761</td>\n",
       "      <td>0.95</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 5...</td>\n",
       "      <td>0.762915</td>\n",
       "      <td>0.778598</td>\n",
       "      <td>0.772140</td>\n",
       "      <td>0.771218</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.194152</td>\n",
       "      <td>1.014803</td>\n",
       "      <td>29.102957</td>\n",
       "      <td>3.106597</td>\n",
       "      <td>0.95</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 5...</td>\n",
       "      <td>0.762454</td>\n",
       "      <td>0.775830</td>\n",
       "      <td>0.770987</td>\n",
       "      <td>0.769757</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28.961356</td>\n",
       "      <td>1.188357</td>\n",
       "      <td>38.207479</td>\n",
       "      <td>2.649415</td>\n",
       "      <td>0.95</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>22</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 5...</td>\n",
       "      <td>0.762454</td>\n",
       "      <td>0.776753</td>\n",
       "      <td>0.768220</td>\n",
       "      <td>0.769142</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>34.085973</td>\n",
       "      <td>1.094185</td>\n",
       "      <td>35.682373</td>\n",
       "      <td>1.546781</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 1...</td>\n",
       "      <td>0.757149</td>\n",
       "      <td>0.773985</td>\n",
       "      <td>0.767758</td>\n",
       "      <td>0.766298</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28.665853</td>\n",
       "      <td>4.454135</td>\n",
       "      <td>16.143958</td>\n",
       "      <td>3.393197</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 1...</td>\n",
       "      <td>0.756227</td>\n",
       "      <td>0.770526</td>\n",
       "      <td>0.765913</td>\n",
       "      <td>0.764222</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29.857706</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>38.198259</td>\n",
       "      <td>1.029127</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 1...</td>\n",
       "      <td>0.753459</td>\n",
       "      <td>0.769142</td>\n",
       "      <td>0.768220</td>\n",
       "      <td>0.763607</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.521135</td>\n",
       "      <td>2.049888</td>\n",
       "      <td>21.400431</td>\n",
       "      <td>0.377896</td>\n",
       "      <td>0.95</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 5...</td>\n",
       "      <td>0.755535</td>\n",
       "      <td>0.768450</td>\n",
       "      <td>0.763607</td>\n",
       "      <td>0.762531</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32.505357</td>\n",
       "      <td>2.888167</td>\n",
       "      <td>31.000571</td>\n",
       "      <td>0.581728</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'cvec__max_df': 0.95, 'cvec__max_features': 1...</td>\n",
       "      <td>0.746310</td>\n",
       "      <td>0.761531</td>\n",
       "      <td>0.752768</td>\n",
       "      <td>0.753536</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       22.601203      0.481789        22.433740        1.171363   \n",
       "7       20.426651      0.517186        23.454713        1.252792   \n",
       "17      35.251082      2.103824        41.037591        1.120761   \n",
       "15      28.194152      1.014803        29.102957        3.106597   \n",
       "16      28.961356      1.188357        38.207479        2.649415   \n",
       "24      34.085973      1.094185        35.682373        1.546781   \n",
       "26      28.665853      4.454135        16.143958        3.393197   \n",
       "22      29.857706      0.792714        38.198259        1.029127   \n",
       "10      24.521135      2.049888        21.400431        0.377896   \n",
       "19      32.505357      2.888167        31.000571        0.581728   \n",
       "\n",
       "   param_cvec__max_df param_cvec__max_features param_cvec__ngram_range  \\\n",
       "8                0.95                      300                  (1, 2)   \n",
       "7                0.95                      300                  (1, 2)   \n",
       "17               0.95                      500                  (1, 2)   \n",
       "15               0.95                      500                  (1, 2)   \n",
       "16               0.95                      500                  (1, 2)   \n",
       "24               0.95                     1000                  (1, 2)   \n",
       "26               0.95                     1000                  (1, 2)   \n",
       "22               0.95                     1000                  (1, 2)   \n",
       "10               0.95                      500                  (1, 2)   \n",
       "19               0.95                     1000                  (1, 2)   \n",
       "\n",
       "   param_cvec__stop_words param_knn__n_neighbors  \\\n",
       "8                    None                     24   \n",
       "7                    None                     22   \n",
       "17                   None                     24   \n",
       "15                   None                     20   \n",
       "16                   None                     22   \n",
       "24                   None                     20   \n",
       "26                   None                     24   \n",
       "22                   None                     16   \n",
       "10                   None                     10   \n",
       "19                   None                     10   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "8   {'cvec__max_df': 0.95, 'cvec__max_features': 3...           0.770756   \n",
       "7   {'cvec__max_df': 0.95, 'cvec__max_features': 3...           0.768681   \n",
       "17  {'cvec__max_df': 0.95, 'cvec__max_features': 5...           0.762915   \n",
       "15  {'cvec__max_df': 0.95, 'cvec__max_features': 5...           0.762454   \n",
       "16  {'cvec__max_df': 0.95, 'cvec__max_features': 5...           0.762454   \n",
       "24  {'cvec__max_df': 0.95, 'cvec__max_features': 1...           0.757149   \n",
       "26  {'cvec__max_df': 0.95, 'cvec__max_features': 1...           0.756227   \n",
       "22  {'cvec__max_df': 0.95, 'cvec__max_features': 1...           0.753459   \n",
       "10  {'cvec__max_df': 0.95, 'cvec__max_features': 5...           0.755535   \n",
       "19  {'cvec__max_df': 0.95, 'cvec__max_features': 1...           0.746310   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "8            0.782518           0.773063         0.775446        0.005089   \n",
       "7            0.780673           0.773755         0.774370        0.004915   \n",
       "17           0.778598           0.772140         0.771218        0.006436   \n",
       "15           0.775830           0.770987         0.769757        0.005530   \n",
       "16           0.776753           0.768220         0.769142        0.005874   \n",
       "24           0.773985           0.767758         0.766298        0.006950   \n",
       "26           0.770526           0.765913         0.764222        0.005959   \n",
       "22           0.769142           0.768220         0.763607        0.007185   \n",
       "10           0.768450           0.763607         0.762531        0.005327   \n",
       "19           0.761531           0.752768         0.753536        0.006238   \n",
       "\n",
       "    rank_test_score  \n",
       "8                 1  \n",
       "7                 2  \n",
       "17                3  \n",
       "15                4  \n",
       "16                5  \n",
       "24                6  \n",
       "26                7  \n",
       "22                8  \n",
       "10                9  \n",
       "19               10  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('============= KNN =============')\n",
    "print(f'best cv score: {gs_cvec_knn.best_score_}') # through cross-validation\n",
    "print('=============')\n",
    "print(f'best params:') # best parameters\n",
    "[print(f'{ind}: {val}') for ind, val in gs_cvec_knn.best_params_.items()];\n",
    "print('=============')\n",
    "pred = gs_cvec_knn.predict(Z_test)\n",
    "\n",
    "print(f'train score: {gs_cvec_knn.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs_cvec_knn.score(Z_test, y_test)}')\n",
    "\n",
    "print('=============')\n",
    "pd.DataFrame(gs_cvec_knn.cv_results_).sort_values(by='mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- As expected, the KNN performs better when we use fewer number of features. In our case, we case reducing the max number of features to 300-500 would give us the best results. \n",
    "- Similar to what we observed with Logistic Regression, when we play with max features in the model, we can see that increasing the max feature does not help with the test/cv score and only helps with the train score, meaning that using features more that a threshold (here 300 to 500) will cause overfitting. \n",
    "- Gridsearch analysis shows that using `max_df` of 0.95 gives us the best results.\n",
    "- Using stopewords are observed to deteriorate model performance so we decided to go with no stop words. \n",
    "- Using ngrams (1, 2) improves the scores slightly, so we decided to choose that.\n",
    "- Best estimators are the ones that use `n_neghbors` in the rang of 10-20 (please see the below graph).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masou\\AppData\\Local\\Temp\\ipykernel_1756\\1180272911.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  results[results['mean_test_score'].notnull()].groupby('param_knn__n_neighbors').mean()['mean_test_score'].plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model performance for different values of n_neghbors\n",
    "results = pd.DataFrame(gs_cvec_knn.cv_results_)\n",
    "results[results['mean_test_score'].notnull()].groupby('param_knn__n_neighbors').mean()['mean_test_score'].plot()\n",
    "plt.xlabel('number of neighbors in KNN')\n",
    "plt.ylabel('best score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graph above, varying the number of neighbors above 8 does not impact the performance of the KNN estimator that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will use multinomial Naive Bayes estimator along with CountVectorizer to see if this model performs any better that the previous estimators.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [3000, 5000],\n",
       "                         &#x27;cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [3000, 5000],\n",
       "                         &#x27;cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()), (&#x27;mnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [1.0, 0.8, 0.5],\n",
       "                         'cvec__max_features': [3000, 5000],\n",
       "                         'cvec__min_df': [2, 4],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cvec__stop_words': [None, 'english']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X train and test best on only the text column\n",
    "Z_train = X_train['text']\n",
    "Z_test = X_test['text']\n",
    "# create a pipe instance \n",
    "pipe_cvec_mnb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# decide on what parameters to modify for transformer and estimator\n",
    "params_cvec_mnb = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "    'cvec__max_df': [1.0, 0.8, 0.5],\n",
    "    'cvec__min_df': [2, 4],\n",
    "    'cvec__max_features': [3000, 5000],\n",
    "\n",
    "}\n",
    "\n",
    "gs_cvec_mnb = GridSearchCV(pipe_cvec_mnb,\n",
    "                 param_grid=params_cvec_mnb,\n",
    "                 n_jobs=-1,\n",
    "                 cv=3,\n",
    "                 verbose=1)\n",
    "\n",
    "gs_cvec_mnb.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= MN Naive Bayes =============\n",
      "best cv score: 0.8618542435424353\n",
      "=============\n",
      "best params:\n",
      "cvec__max_df: 0.8\n",
      "cvec__max_features: 5000\n",
      "cvec__min_df: 4\n",
      "cvec__ngram_range: (1, 1)\n",
      "cvec__stop_words: None\n",
      "=============\n",
      "train score: 0.8716174661746617\n",
      "test score: 0.8555179833999386\n",
      "=============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>param_cvec__stop_words</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.297384</td>\n",
       "      <td>0.188609</td>\n",
       "      <td>3.833857</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.8, 'cvec__max_features': 50...</td>\n",
       "      <td>0.856089</td>\n",
       "      <td>0.863007</td>\n",
       "      <td>0.866467</td>\n",
       "      <td>0.861854</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.312376</td>\n",
       "      <td>0.079441</td>\n",
       "      <td>3.707902</td>\n",
       "      <td>0.057494</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.8, 'cvec__max_features': 50...</td>\n",
       "      <td>0.854935</td>\n",
       "      <td>0.862085</td>\n",
       "      <td>0.865083</td>\n",
       "      <td>0.860701</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.178606</td>\n",
       "      <td>0.451447</td>\n",
       "      <td>2.943527</td>\n",
       "      <td>0.144641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 1.0, 'cvec__max_features': 50...</td>\n",
       "      <td>0.853090</td>\n",
       "      <td>0.862315</td>\n",
       "      <td>0.866467</td>\n",
       "      <td>0.860624</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.246121</td>\n",
       "      <td>0.131514</td>\n",
       "      <td>3.184285</td>\n",
       "      <td>0.208740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 1.0, 'cvec__max_features': 50...</td>\n",
       "      <td>0.852860</td>\n",
       "      <td>0.861854</td>\n",
       "      <td>0.866697</td>\n",
       "      <td>0.860470</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7.608717</td>\n",
       "      <td>0.282308</td>\n",
       "      <td>4.609104</td>\n",
       "      <td>0.262487</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 50...</td>\n",
       "      <td>0.855166</td>\n",
       "      <td>0.861854</td>\n",
       "      <td>0.862085</td>\n",
       "      <td>0.859702</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.386199</td>\n",
       "      <td>0.187670</td>\n",
       "      <td>4.561079</td>\n",
       "      <td>0.221858</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 50...</td>\n",
       "      <td>0.854474</td>\n",
       "      <td>0.860932</td>\n",
       "      <td>0.862085</td>\n",
       "      <td>0.859164</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7.141134</td>\n",
       "      <td>0.243498</td>\n",
       "      <td>4.576399</td>\n",
       "      <td>0.539678</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 30...</td>\n",
       "      <td>0.853090</td>\n",
       "      <td>0.861624</td>\n",
       "      <td>0.861854</td>\n",
       "      <td>0.858856</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.751924</td>\n",
       "      <td>0.131775</td>\n",
       "      <td>4.394756</td>\n",
       "      <td>0.234275</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 30...</td>\n",
       "      <td>0.853090</td>\n",
       "      <td>0.861624</td>\n",
       "      <td>0.861854</td>\n",
       "      <td>0.858856</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.659574</td>\n",
       "      <td>0.112614</td>\n",
       "      <td>3.244684</td>\n",
       "      <td>0.227262</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.8, 'cvec__max_features': 30...</td>\n",
       "      <td>0.852860</td>\n",
       "      <td>0.857472</td>\n",
       "      <td>0.863930</td>\n",
       "      <td>0.858087</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.791603</td>\n",
       "      <td>0.157152</td>\n",
       "      <td>3.427759</td>\n",
       "      <td>0.198104</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.8, 'cvec__max_features': 30...</td>\n",
       "      <td>0.853090</td>\n",
       "      <td>0.856780</td>\n",
       "      <td>0.863699</td>\n",
       "      <td>0.857857</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "28       6.297384      0.188609         3.833857        0.056644   \n",
       "24       6.312376      0.079441         3.707902        0.057494   \n",
       "8        6.178606      0.451447         2.943527        0.144641   \n",
       "12       6.246121      0.131514         3.184285        0.208740   \n",
       "44       7.608717      0.282308         4.609104        0.262487   \n",
       "40       7.386199      0.187670         4.561079        0.221858   \n",
       "36       7.141134      0.243498         4.576399        0.539678   \n",
       "32       6.751924      0.131775         4.394756        0.234275   \n",
       "16       5.659574      0.112614         3.244684        0.227262   \n",
       "20       5.791603      0.157152         3.427759        0.198104   \n",
       "\n",
       "   param_cvec__max_df param_cvec__max_features param_cvec__min_df  \\\n",
       "28                0.8                     5000                  4   \n",
       "24                0.8                     5000                  2   \n",
       "8                 1.0                     5000                  2   \n",
       "12                1.0                     5000                  4   \n",
       "44                0.5                     5000                  4   \n",
       "40                0.5                     5000                  2   \n",
       "36                0.5                     3000                  4   \n",
       "32                0.5                     3000                  2   \n",
       "16                0.8                     3000                  2   \n",
       "20                0.8                     3000                  4   \n",
       "\n",
       "   param_cvec__ngram_range param_cvec__stop_words  \\\n",
       "28                  (1, 1)                   None   \n",
       "24                  (1, 1)                   None   \n",
       "8                   (1, 1)                   None   \n",
       "12                  (1, 1)                   None   \n",
       "44                  (1, 1)                   None   \n",
       "40                  (1, 1)                   None   \n",
       "36                  (1, 1)                   None   \n",
       "32                  (1, 1)                   None   \n",
       "16                  (1, 1)                   None   \n",
       "20                  (1, 1)                   None   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "28  {'cvec__max_df': 0.8, 'cvec__max_features': 50...           0.856089   \n",
       "24  {'cvec__max_df': 0.8, 'cvec__max_features': 50...           0.854935   \n",
       "8   {'cvec__max_df': 1.0, 'cvec__max_features': 50...           0.853090   \n",
       "12  {'cvec__max_df': 1.0, 'cvec__max_features': 50...           0.852860   \n",
       "44  {'cvec__max_df': 0.5, 'cvec__max_features': 50...           0.855166   \n",
       "40  {'cvec__max_df': 0.5, 'cvec__max_features': 50...           0.854474   \n",
       "36  {'cvec__max_df': 0.5, 'cvec__max_features': 30...           0.853090   \n",
       "32  {'cvec__max_df': 0.5, 'cvec__max_features': 30...           0.853090   \n",
       "16  {'cvec__max_df': 0.8, 'cvec__max_features': 30...           0.852860   \n",
       "20  {'cvec__max_df': 0.8, 'cvec__max_features': 30...           0.853090   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "28           0.863007           0.866467         0.861854        0.004315   \n",
       "24           0.862085           0.865083         0.860701        0.004257   \n",
       "8            0.862315           0.866467         0.860624        0.005590   \n",
       "12           0.861854           0.866697         0.860470        0.005733   \n",
       "44           0.861854           0.862085         0.859702        0.003209   \n",
       "40           0.860932           0.862085         0.859164        0.003349   \n",
       "36           0.861624           0.861854         0.858856        0.004078   \n",
       "32           0.861624           0.861854         0.858856        0.004078   \n",
       "16           0.857472           0.863930         0.858087        0.004540   \n",
       "20           0.856780           0.863699         0.857857        0.004397   \n",
       "\n",
       "    rank_test_score  \n",
       "28                1  \n",
       "24                2  \n",
       "8                 3  \n",
       "12                4  \n",
       "44                5  \n",
       "40                6  \n",
       "36                7  \n",
       "32                7  \n",
       "16                9  \n",
       "20               10  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('============= MN Naive Bayes =============')\n",
    "print(f'best cv score: {gs_cvec_mnb.best_score_}') # through cross-validation\n",
    "print('=============')\n",
    "print(f'best params:') # best parameters\n",
    "[print(f'{ind}: {val}') for ind, val in gs_cvec_mnb.best_params_.items()];\n",
    "print('=============')\n",
    "pred = gs_cvec_mnb.predict(Z_test)\n",
    "\n",
    "print(f'train score: {gs_cvec_mnb.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs_cvec_mnb.score(Z_test, y_test)}')\n",
    "\n",
    "print('=============')\n",
    "pd.DataFrame(gs_cvec_mnb.cv_results_).sort_values(by='mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Similar to what we have observed with the previous models, it looks like whenever we increase the max features above a certain threshold, the model starts overfitting the data without that much of improvement in performance against the test/cv data. \n",
    "- In this case, 3000-5000 `max_features` gives us the best performance so we used this. \n",
    "- Bigrams and trigrams do not improve the estimator's performance. \n",
    "- Similarly, 'english' stopwords did not seem to help with the estimator's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg vs. KNN vs. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above mentioned models were used along with CountVectorizer in order to classify the subreddit listings in r/offmychest and r/relationship_advice subreddits. The following scores (accuracy score) were achieved for each of the estimator's best performance on test data:\n",
    "\n",
    "| Estimator | Score |\n",
    "| -------- | ------- |\n",
    "| Logistic Regression  | 0.88   |\n",
    "| KNN | 0.76     |\n",
    "| Multinomial Naive Bayes| 0.85    |\n",
    "\n",
    "Based on our observations, KNN showed the poorest performance. Logistic Regression and Naive Bayes show a comparable performance on the test dataset while Naive Bayes is faster. For the next part, we will use Naive Bayes and see how it performs with the `TfidfVectorizer` and `CountVectorizer` transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tfidfVecotizer` vs. `CountVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section, we will see how `TfidfVectorizer` performs against `CountVectorizer` when using Naive Bayes as our estimator. From the previous section, here is the best performance for the CountVectorizer transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= CountVectorizer with MN Naive Bayes =============\n",
      "best cv score: 0.8618542435424353\n",
      "train score: 0.8716174661746617\n",
      "test score: 0.8555179833999386\n"
     ]
    }
   ],
   "source": [
    "print('============= CountVectorizer with MN Naive Bayes =============')\n",
    "print(f'best cv score: {gs_cvec_mnb.best_score_}') # through cross-validation\n",
    "pred = gs_cvec_mnb.predict(Z_test)\n",
    "print(f'train score: {gs_cvec_mnb.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs_cvec_mnb.score(Z_test, y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us repeat the same calculations with TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;tfidf__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;tfidf__max_features&#x27;: [3000, 5000],\n",
       "                         &#x27;tfidf__min_df&#x27;: [2, 4],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                         &#x27;tfidf__norm&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, None],\n",
       "                         &#x27;tfidf__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;tfidf__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;tfidf__max_features&#x27;: [3000, 5000],\n",
       "                         &#x27;tfidf__min_df&#x27;: [2, 4],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                         &#x27;tfidf__norm&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, None],\n",
       "                         &#x27;tfidf__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;mnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tfidf__max_df': [1.0, 0.8, 0.5],\n",
       "                         'tfidf__max_features': [3000, 5000],\n",
       "                         'tfidf__min_df': [2, 4],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'tfidf__norm': ['l1', 'l2', None],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X train and test best on only the text column\n",
    "Z_train = X_train['text']\n",
    "Z_test = X_test['text']\n",
    "# create a pipe instance \n",
    "pipe_tfidf_mnb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# decide on what parameters to modify for transformer and estimator\n",
    "params_tfidf_mnb = {\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_df': [1.0, 0.8, 0.5],\n",
    "    'tfidf__min_df': [2, 4],\n",
    "    'tfidf__max_features': [3000, 5000],\n",
    "    'tfidf__norm': ['l1', 'l2', None], # 'l1', \n",
    "\n",
    "}\n",
    "\n",
    "gs_tfidf_mnb = GridSearchCV(pipe_tfidf_mnb,\n",
    "                 param_grid=params_tfidf_mnb,\n",
    "                 n_jobs=-1,\n",
    "                 cv=3,\n",
    "                 verbose=1)\n",
    "\n",
    "gs_tfidf_mnb.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= TfidfVectorizer with Naive Bayes =============\n",
      "best cv score: 0.862238622386224\n",
      "=============\n",
      "best params:\n",
      "tfidf__max_df: 0.8\n",
      "tfidf__max_features: 5000\n",
      "tfidf__min_df: 4\n",
      "tfidf__ngram_range: (1, 1)\n",
      "tfidf__norm: None\n",
      "tfidf__stop_words: None\n",
      "=============\n",
      "train score: 0.878459409594096\n",
      "test score: 0.8524438979403628\n",
      "=============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tfidf__max_df</th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__min_df</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_tfidf__stop_words</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>10.256163</td>\n",
       "      <td>1.078352</td>\n",
       "      <td>6.066869</td>\n",
       "      <td>0.232136</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 0.8, 'tfidf__max_features': ...</td>\n",
       "      <td>0.858856</td>\n",
       "      <td>0.864622</td>\n",
       "      <td>0.863238</td>\n",
       "      <td>0.862239</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>11.055575</td>\n",
       "      <td>0.619728</td>\n",
       "      <td>5.970418</td>\n",
       "      <td>0.321915</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 0.8, 'tfidf__max_features': ...</td>\n",
       "      <td>0.857472</td>\n",
       "      <td>0.864391</td>\n",
       "      <td>0.862546</td>\n",
       "      <td>0.861470</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.574344</td>\n",
       "      <td>0.413404</td>\n",
       "      <td>3.397216</td>\n",
       "      <td>0.108963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 1.0, 'tfidf__max_features': ...</td>\n",
       "      <td>0.857011</td>\n",
       "      <td>0.863699</td>\n",
       "      <td>0.863469</td>\n",
       "      <td>0.861393</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.181171</td>\n",
       "      <td>0.345824</td>\n",
       "      <td>3.695327</td>\n",
       "      <td>0.050785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 1.0, 'tfidf__max_features': ...</td>\n",
       "      <td>0.857011</td>\n",
       "      <td>0.862777</td>\n",
       "      <td>0.863469</td>\n",
       "      <td>0.861085</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9.920509</td>\n",
       "      <td>0.379328</td>\n",
       "      <td>5.693457</td>\n",
       "      <td>0.382634</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 0.8, 'tfidf__max_features': ...</td>\n",
       "      <td>0.857934</td>\n",
       "      <td>0.862777</td>\n",
       "      <td>0.862546</td>\n",
       "      <td>0.861085</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.252201</td>\n",
       "      <td>0.782800</td>\n",
       "      <td>4.045300</td>\n",
       "      <td>0.319857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 1.0, 'tfidf__max_features': ...</td>\n",
       "      <td>0.858164</td>\n",
       "      <td>0.862777</td>\n",
       "      <td>0.862315</td>\n",
       "      <td>0.861085</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8.012227</td>\n",
       "      <td>0.212582</td>\n",
       "      <td>4.860599</td>\n",
       "      <td>0.325511</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 0.8, 'tfidf__max_features': ...</td>\n",
       "      <td>0.857934</td>\n",
       "      <td>0.862777</td>\n",
       "      <td>0.862315</td>\n",
       "      <td>0.861009</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.454781</td>\n",
       "      <td>0.160350</td>\n",
       "      <td>2.699809</td>\n",
       "      <td>0.059134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 1.0, 'tfidf__max_features': ...</td>\n",
       "      <td>0.857472</td>\n",
       "      <td>0.862777</td>\n",
       "      <td>0.862315</td>\n",
       "      <td>0.860855</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>29.422152</td>\n",
       "      <td>2.037504</td>\n",
       "      <td>12.581493</td>\n",
       "      <td>0.726590</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 0.8, 'tfidf__max_features': ...</td>\n",
       "      <td>0.855166</td>\n",
       "      <td>0.857934</td>\n",
       "      <td>0.860009</td>\n",
       "      <td>0.857703</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>18.287188</td>\n",
       "      <td>0.459608</td>\n",
       "      <td>6.588117</td>\n",
       "      <td>0.759390</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfidf__max_df': 0.5, 'tfidf__max_features': ...</td>\n",
       "      <td>0.854474</td>\n",
       "      <td>0.860240</td>\n",
       "      <td>0.858164</td>\n",
       "      <td>0.857626</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "88       10.256163      1.078352         6.066869        0.232136   \n",
       "76       11.055575      0.619728         5.970418        0.321915   \n",
       "28        6.574344      0.413404         3.397216        0.108963   \n",
       "40        7.181171      0.345824         3.695327        0.050785   \n",
       "64        9.920509      0.379328         5.693457        0.382634   \n",
       "16        7.252201      0.782800         4.045300        0.319857   \n",
       "52        8.012227      0.212582         4.860599        0.325511   \n",
       "4         5.454781      0.160350         2.699809        0.059134   \n",
       "82       29.422152      2.037504        12.581493        0.726590   \n",
       "142      18.287188      0.459608         6.588117        0.759390   \n",
       "\n",
       "    param_tfidf__max_df param_tfidf__max_features param_tfidf__min_df  \\\n",
       "88                  0.8                      5000                   4   \n",
       "76                  0.8                      5000                   2   \n",
       "28                  1.0                      5000                   2   \n",
       "40                  1.0                      5000                   4   \n",
       "64                  0.8                      3000                   4   \n",
       "16                  1.0                      3000                   4   \n",
       "52                  0.8                      3000                   2   \n",
       "4                   1.0                      3000                   2   \n",
       "82                  0.8                      5000                   2   \n",
       "142                 0.5                      5000                   4   \n",
       "\n",
       "    param_tfidf__ngram_range param_tfidf__norm param_tfidf__stop_words  \\\n",
       "88                    (1, 1)              None                    None   \n",
       "76                    (1, 1)              None                    None   \n",
       "28                    (1, 1)              None                    None   \n",
       "40                    (1, 1)              None                    None   \n",
       "64                    (1, 1)              None                    None   \n",
       "16                    (1, 1)              None                    None   \n",
       "52                    (1, 1)              None                    None   \n",
       "4                     (1, 1)              None                    None   \n",
       "82                    (1, 2)              None                    None   \n",
       "142                   (1, 2)              None                    None   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "88   {'tfidf__max_df': 0.8, 'tfidf__max_features': ...           0.858856   \n",
       "76   {'tfidf__max_df': 0.8, 'tfidf__max_features': ...           0.857472   \n",
       "28   {'tfidf__max_df': 1.0, 'tfidf__max_features': ...           0.857011   \n",
       "40   {'tfidf__max_df': 1.0, 'tfidf__max_features': ...           0.857011   \n",
       "64   {'tfidf__max_df': 0.8, 'tfidf__max_features': ...           0.857934   \n",
       "16   {'tfidf__max_df': 1.0, 'tfidf__max_features': ...           0.858164   \n",
       "52   {'tfidf__max_df': 0.8, 'tfidf__max_features': ...           0.857934   \n",
       "4    {'tfidf__max_df': 1.0, 'tfidf__max_features': ...           0.857472   \n",
       "82   {'tfidf__max_df': 0.8, 'tfidf__max_features': ...           0.855166   \n",
       "142  {'tfidf__max_df': 0.5, 'tfidf__max_features': ...           0.854474   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "88            0.864622           0.863238         0.862239        0.002458   \n",
       "76            0.864391           0.862546         0.861470        0.002925   \n",
       "28            0.863699           0.863469         0.861393        0.003100   \n",
       "40            0.862777           0.863469         0.861085        0.002895   \n",
       "64            0.862777           0.862546         0.861085        0.002231   \n",
       "16            0.862777           0.862315         0.861085        0.002074   \n",
       "52            0.862777           0.862315         0.861009        0.002183   \n",
       "4             0.862777           0.862315         0.860855        0.002399   \n",
       "82            0.857934           0.860009         0.857703        0.001984   \n",
       "142           0.860240           0.858164         0.857626        0.002384   \n",
       "\n",
       "     rank_test_score  \n",
       "88                 1  \n",
       "76                 2  \n",
       "28                 3  \n",
       "40                 4  \n",
       "64                 4  \n",
       "16                 4  \n",
       "52                 7  \n",
       "4                  8  \n",
       "82                 9  \n",
       "142               10  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('============= TfidfVectorizer with Naive Bayes =============')\n",
    "print(f'best cv score: {gs_tfidf_mnb.best_score_}') # through cross-validation\n",
    "print('=============')\n",
    "print(f'best params:') # best parameters\n",
    "[print(f'{ind}: {val}') for ind, val in gs_tfidf_mnb.best_params_.items()];\n",
    "print('=============')\n",
    "pred = gs_tfidf_mnb.predict(Z_test)\n",
    "\n",
    "print(f'train score: {gs_tfidf_mnb.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs_tfidf_mnb.score(Z_test, y_test)}')\n",
    "\n",
    "print('=============')\n",
    "pd.DataFrame(gs_tfidf_mnb.cv_results_).sort_values(by='mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the estimators performance for `TfidfVectorizer` and `CountVectorizer`, we can see both transformers have similar performances when used along with the Naive Bayes and no one outperformed the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using both text and numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will try to use both text data and also the numerical features we extracted previously from the listings (the length of the columns and the sentiment of listings) to see if our estimator can do any better. To do this, we will have to create a column transfer operator that performs different operations on different columns and then use that in a pipeline with our logistic regression estimator (more on this here: https://stackoverflow.com/questions/63467815/how-to-access-columntransformer-elements-in-gridsearchcv). <br>\n",
    "The reason we use logistic regression is the fact that we will have numeric data that are not necessarily integers and although Naive Bayes library in sklearn works with none-integer data, in the documentation it has stated otherwise.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>Forgive my format and spelling, I’m quite upse...</td>\n",
       "      <td>398</td>\n",
       "      <td>-0.2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9517</th>\n",
       "      <td>Im running out of ideas. I myself am also a de...</td>\n",
       "      <td>269</td>\n",
       "      <td>-0.6616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>First of all, English is  not my first languag...</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.4099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  word_count  sentiment\n",
       "3444  Forgive my format and spelling, I’m quite upse...         398    -0.2011\n",
       "9517  Im running out of ideas. I myself am also a de...         269    -0.6616\n",
       "3966  First of all, English is  not my first languag...         161    -0.4099"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above three features, we will use CountVectorizer on the text column while using StandardScaler for the word_count and sentiment columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;ctx&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;sc&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;word_count&#x27;,\n",
       "                                                                          &#x27;sentiment&#x27;]),\n",
       "                                                                        (&#x27;cvec&#x27;,\n",
       "                                                                         CountVectorizer(),\n",
       "                                                                         &#x27;text&#x27;)])),\n",
       "                                       (&#x27;logr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;ctx__cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;ctx__cvec__max_features&#x27;: [3000],\n",
       "                         &#x27;ctx__cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;ctx__cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;ctx__cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;logr__C&#x27;: [0.1, 0.5, 1],\n",
       "                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;, None]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;ctx&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;sc&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;word_count&#x27;,\n",
       "                                                                          &#x27;sentiment&#x27;]),\n",
       "                                                                        (&#x27;cvec&#x27;,\n",
       "                                                                         CountVectorizer(),\n",
       "                                                                         &#x27;text&#x27;)])),\n",
       "                                       (&#x27;logr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;ctx__cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;ctx__cvec__max_features&#x27;: [3000],\n",
       "                         &#x27;ctx__cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;ctx__cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;ctx__cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;logr__C&#x27;: [0.1, 0.5, 1],\n",
       "                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;, None]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ctx&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;sc&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;word_count&#x27;, &#x27;sentiment&#x27;]),\n",
       "                                                 (&#x27;cvec&#x27;, CountVectorizer(),\n",
       "                                                  &#x27;text&#x27;)])),\n",
       "                (&#x27;logr&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ctx: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;sc&#x27;, StandardScaler(),\n",
       "                                 [&#x27;word_count&#x27;, &#x27;sentiment&#x27;]),\n",
       "                                (&#x27;cvec&#x27;, CountVectorizer(), &#x27;text&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">sc</label><div class=\"sk-toggleable__content\"><pre>[&#x27;word_count&#x27;, &#x27;sentiment&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cvec</label><div class=\"sk-toggleable__content\"><pre>text</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('ctx',\n",
       "                                        ColumnTransformer(transformers=[('sc',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['word_count',\n",
       "                                                                          'sentiment']),\n",
       "                                                                        ('cvec',\n",
       "                                                                         CountVectorizer(),\n",
       "                                                                         'text')])),\n",
       "                                       ('logr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'ctx__cvec__max_df': [1.0, 0.8, 0.5],\n",
       "                         'ctx__cvec__max_features': [3000],\n",
       "                         'ctx__cvec__min_df': [2, 4],\n",
       "                         'ctx__cvec__ngram_range': [(1, 2)],\n",
       "                         'ctx__cvec__stop_words': [None, 'english'],\n",
       "                         'logr__C': [0.1, 0.5, 1],\n",
       "                         'logr__penalty': ['l2', None]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X train and test best on only the text column\n",
    "Z_train = X_train.copy()\n",
    "Z_test = X_test.copy()\n",
    "\n",
    "# create the column transformer\n",
    "ctx = ColumnTransformer(transformers = \n",
    "                                 [('sc', StandardScaler(), ['word_count', 'sentiment']),\n",
    "# make sure this is not in a list as countvectorizer doesnt work with dataframe and has to be one column\n",
    "                                  ('cvec', CountVectorizer(), 'text')]) \n",
    "\n",
    "# create a pipe instance \n",
    "pipe_ctx_logr = Pipeline([('ctx', ctx),\n",
    "                          ('logr', LogisticRegression())])\n",
    "\n",
    "# decide on what parameters to modify for transformer and estimator\n",
    "pipe_ctx_logr_params = {\n",
    "    'ctx__cvec__stop_words': [None, 'english'],\n",
    "    'ctx__cvec__ngram_range': [(1, 2)],\n",
    "    'ctx__cvec__max_df': [1.0, 0.8, 0.5],\n",
    "    'ctx__cvec__min_df': [2, 4],\n",
    "    'ctx__cvec__max_features': [3000], #, 5000],\n",
    "\n",
    "    'logr__C': [0.1, 0.5, 1],\n",
    "    'logr__penalty': ['l2', None] #, None], #, 'elasticnet', 'none']\n",
    "}\n",
    "\n",
    "gs_ctx_logr = GridSearchCV(pipe_ctx_logr,\n",
    "                  param_grid=pipe_ctx_logr_params,\n",
    "                  n_jobs=-1,\n",
    "                  cv=3,\n",
    "                  verbose=3)\n",
    "\n",
    "gs_ctx_logr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= LogReg with text and numerical features =============\n",
      "best cv score: 0.8802275522755227\n",
      "=============\n",
      "best params:\n",
      "ctx__cvec__max_df: 0.5\n",
      "ctx__cvec__max_features: 3000\n",
      "ctx__cvec__min_df: 2\n",
      "ctx__cvec__ngram_range: (1, 2)\n",
      "ctx__cvec__stop_words: english\n",
      "logr__C: 0.1\n",
      "logr__penalty: l2\n",
      "=============\n",
      "train score: 0.9545664206642066\n",
      "test score: 0.8853366123578236\n",
      "=============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ctx__cvec__max_df</th>\n",
       "      <th>param_ctx__cvec__max_features</th>\n",
       "      <th>param_ctx__cvec__min_df</th>\n",
       "      <th>param_ctx__cvec__ngram_range</th>\n",
       "      <th>param_ctx__cvec__stop_words</th>\n",
       "      <th>param_logr__C</th>\n",
       "      <th>param_logr__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>16.177509</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>5.189768</td>\n",
       "      <td>0.334046</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 0.5, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.881919</td>\n",
       "      <td>0.881688</td>\n",
       "      <td>0.877076</td>\n",
       "      <td>0.880228</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>16.419201</td>\n",
       "      <td>1.741717</td>\n",
       "      <td>4.211856</td>\n",
       "      <td>0.165992</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 0.5, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.881458</td>\n",
       "      <td>0.881227</td>\n",
       "      <td>0.876614</td>\n",
       "      <td>0.879766</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17.699712</td>\n",
       "      <td>0.562648</td>\n",
       "      <td>4.780618</td>\n",
       "      <td>0.745841</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 0.8, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.880996</td>\n",
       "      <td>0.880766</td>\n",
       "      <td>0.876153</td>\n",
       "      <td>0.879305</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.997164</td>\n",
       "      <td>0.257010</td>\n",
       "      <td>4.405334</td>\n",
       "      <td>0.133628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 1.0, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.880996</td>\n",
       "      <td>0.880766</td>\n",
       "      <td>0.876153</td>\n",
       "      <td>0.879305</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.619483</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>4.887965</td>\n",
       "      <td>0.555054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 1.0, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.880535</td>\n",
       "      <td>0.880996</td>\n",
       "      <td>0.874769</td>\n",
       "      <td>0.878767</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16.305979</td>\n",
       "      <td>0.334450</td>\n",
       "      <td>4.907816</td>\n",
       "      <td>0.311614</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 0.8, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.880535</td>\n",
       "      <td>0.880996</td>\n",
       "      <td>0.874769</td>\n",
       "      <td>0.878767</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.798360</td>\n",
       "      <td>0.078190</td>\n",
       "      <td>4.485559</td>\n",
       "      <td>0.106355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 1.0, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.873616</td>\n",
       "      <td>0.873847</td>\n",
       "      <td>0.865775</td>\n",
       "      <td>0.871079</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15.304871</td>\n",
       "      <td>0.470835</td>\n",
       "      <td>3.879043</td>\n",
       "      <td>0.377604</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 0.8, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.873616</td>\n",
       "      <td>0.873847</td>\n",
       "      <td>0.865775</td>\n",
       "      <td>0.871079</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.428017</td>\n",
       "      <td>1.236218</td>\n",
       "      <td>4.539620</td>\n",
       "      <td>0.390428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 1.0, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.874308</td>\n",
       "      <td>0.873616</td>\n",
       "      <td>0.864161</td>\n",
       "      <td>0.870695</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15.625378</td>\n",
       "      <td>0.465499</td>\n",
       "      <td>4.205058</td>\n",
       "      <td>0.084745</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'ctx__cvec__max_df': 0.8, 'ctx__cvec__max_fea...</td>\n",
       "      <td>0.874308</td>\n",
       "      <td>0.873616</td>\n",
       "      <td>0.864161</td>\n",
       "      <td>0.870695</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "54      16.177509      0.480519         5.189768        0.334046   \n",
       "66      16.419201      1.741717         4.211856        0.165992   \n",
       "30      17.699712      0.562648         4.780618        0.745841   \n",
       "6       14.997164      0.257010         4.405334        0.133628   \n",
       "18      15.619483      0.809818         4.887965        0.555054   \n",
       "42      16.305979      0.334450         4.907816        0.311614   \n",
       "8       14.798360      0.078190         4.485559        0.106355   \n",
       "32      15.304871      0.470835         3.879043        0.377604   \n",
       "20      16.428017      1.236218         4.539620        0.390428   \n",
       "44      15.625378      0.465499         4.205058        0.084745   \n",
       "\n",
       "   param_ctx__cvec__max_df param_ctx__cvec__max_features  \\\n",
       "54                     0.5                          3000   \n",
       "66                     0.5                          3000   \n",
       "30                     0.8                          3000   \n",
       "6                      1.0                          3000   \n",
       "18                     1.0                          3000   \n",
       "42                     0.8                          3000   \n",
       "8                      1.0                          3000   \n",
       "32                     0.8                          3000   \n",
       "20                     1.0                          3000   \n",
       "44                     0.8                          3000   \n",
       "\n",
       "   param_ctx__cvec__min_df param_ctx__cvec__ngram_range  \\\n",
       "54                       2                       (1, 2)   \n",
       "66                       4                       (1, 2)   \n",
       "30                       2                       (1, 2)   \n",
       "6                        2                       (1, 2)   \n",
       "18                       4                       (1, 2)   \n",
       "42                       4                       (1, 2)   \n",
       "8                        2                       (1, 2)   \n",
       "32                       2                       (1, 2)   \n",
       "20                       4                       (1, 2)   \n",
       "44                       4                       (1, 2)   \n",
       "\n",
       "   param_ctx__cvec__stop_words param_logr__C param_logr__penalty  \\\n",
       "54                     english           0.1                  l2   \n",
       "66                     english           0.1                  l2   \n",
       "30                     english           0.1                  l2   \n",
       "6                      english           0.1                  l2   \n",
       "18                     english           0.1                  l2   \n",
       "42                     english           0.1                  l2   \n",
       "8                      english           0.5                  l2   \n",
       "32                     english           0.5                  l2   \n",
       "20                     english           0.5                  l2   \n",
       "44                     english           0.5                  l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "54  {'ctx__cvec__max_df': 0.5, 'ctx__cvec__max_fea...           0.881919   \n",
       "66  {'ctx__cvec__max_df': 0.5, 'ctx__cvec__max_fea...           0.881458   \n",
       "30  {'ctx__cvec__max_df': 0.8, 'ctx__cvec__max_fea...           0.880996   \n",
       "6   {'ctx__cvec__max_df': 1.0, 'ctx__cvec__max_fea...           0.880996   \n",
       "18  {'ctx__cvec__max_df': 1.0, 'ctx__cvec__max_fea...           0.880535   \n",
       "42  {'ctx__cvec__max_df': 0.8, 'ctx__cvec__max_fea...           0.880535   \n",
       "8   {'ctx__cvec__max_df': 1.0, 'ctx__cvec__max_fea...           0.873616   \n",
       "32  {'ctx__cvec__max_df': 0.8, 'ctx__cvec__max_fea...           0.873616   \n",
       "20  {'ctx__cvec__max_df': 1.0, 'ctx__cvec__max_fea...           0.874308   \n",
       "44  {'ctx__cvec__max_df': 0.8, 'ctx__cvec__max_fea...           0.874308   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "54           0.881688           0.877076         0.880228        0.002231   \n",
       "66           0.881227           0.876614         0.879766        0.002231   \n",
       "30           0.880766           0.876153         0.879305        0.002231   \n",
       "6            0.880766           0.876153         0.879305        0.002231   \n",
       "18           0.880996           0.874769         0.878767        0.002833   \n",
       "42           0.880996           0.874769         0.878767        0.002833   \n",
       "8            0.873847           0.865775         0.871079        0.003752   \n",
       "32           0.873847           0.865775         0.871079        0.003752   \n",
       "20           0.873616           0.864161         0.870695        0.004629   \n",
       "44           0.873616           0.864161         0.870695        0.004629   \n",
       "\n",
       "    rank_test_score  \n",
       "54                1  \n",
       "66                2  \n",
       "30                3  \n",
       "6                 3  \n",
       "18                5  \n",
       "42                5  \n",
       "8                 7  \n",
       "32                7  \n",
       "20                9  \n",
       "44                9  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('============= LogReg with text and numerical features =============')\n",
    "print(f'best cv score: {gs_ctx_logr.best_score_}') # through cross-validation\n",
    "print('=============')\n",
    "print(f'best params:') # best parameters\n",
    "[print(f'{ind}: {val}') for ind, val in gs_ctx_logr.best_params_.items()];\n",
    "print('=============')\n",
    "pred = gs_ctx_logr.predict(Z_test)\n",
    "\n",
    "print(f'train score: {gs_ctx_logr.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs_ctx_logr.score(Z_test, y_test)}')\n",
    "\n",
    "print('=============')\n",
    "pd.DataFrame(gs_ctx_logr.cv_results_).sort_values(by='mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these results, we can see that using the numerical features (sentiment score and word counts) does not seem to improve the performance of our model. Additionally, the model still suffers from having a relatively high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last part in our model tuning and comparison notebook, we will create a pipline to evaluate whether ensemble based models like random forest could perform well in our problem of classifying two subreddits (offmychest and relationship_advice). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                             (&#x27;rf&#x27;, RandomForestClassifier())]),\n",
       "                   n_iter=150, n_jobs=-1,\n",
       "                   param_distributions={&#x27;cvec__max_df&#x27;: [1.0, 0.8],\n",
       "                                        &#x27;cvec__max_features&#x27;: [1000, 3000],\n",
       "                                        &#x27;cvec__min_df&#x27;: [2],\n",
       "                                        &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                                        &#x27;cvec__stop_words&#x27;: [&#x27;english&#x27;],\n",
       "                                        &#x27;rf__max_depth&#x27;: [None, 10, 100, 500],\n",
       "                                        &#x27;rf__min_samples_leaf&#x27;: [1, 5, 10],\n",
       "                                        &#x27;rf__min_samples_split&#x27;: [2, 8, 20],\n",
       "                                        &#x27;rf__n_estimators&#x27;: [100, 150, 200],\n",
       "                                        &#x27;rf__random_state&#x27;: [42]},\n",
       "                   random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                             (&#x27;rf&#x27;, RandomForestClassifier())]),\n",
       "                   n_iter=150, n_jobs=-1,\n",
       "                   param_distributions={&#x27;cvec__max_df&#x27;: [1.0, 0.8],\n",
       "                                        &#x27;cvec__max_features&#x27;: [1000, 3000],\n",
       "                                        &#x27;cvec__min_df&#x27;: [2],\n",
       "                                        &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                                        &#x27;cvec__stop_words&#x27;: [&#x27;english&#x27;],\n",
       "                                        &#x27;rf__max_depth&#x27;: [None, 10, 100, 500],\n",
       "                                        &#x27;rf__min_samples_leaf&#x27;: [1, 5, 10],\n",
       "                                        &#x27;rf__min_samples_split&#x27;: [2, 8, 20],\n",
       "                                        &#x27;rf__n_estimators&#x27;: [100, 150, 200],\n",
       "                                        &#x27;rf__random_state&#x27;: [42]},\n",
       "                   random_state=42, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()), (&#x27;rf&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                             ('rf', RandomForestClassifier())]),\n",
       "                   n_iter=150, n_jobs=-1,\n",
       "                   param_distributions={'cvec__max_df': [1.0, 0.8],\n",
       "                                        'cvec__max_features': [1000, 3000],\n",
       "                                        'cvec__min_df': [2],\n",
       "                                        'cvec__ngram_range': [(1, 2)],\n",
       "                                        'cvec__stop_words': ['english'],\n",
       "                                        'rf__max_depth': [None, 10, 100, 500],\n",
       "                                        'rf__min_samples_leaf': [1, 5, 10],\n",
       "                                        'rf__min_samples_split': [2, 8, 20],\n",
       "                                        'rf__n_estimators': [100, 150, 200],\n",
       "                                        'rf__random_state': [42]},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X train and test best on only the text column\n",
    "Z_train = X_train['text']\n",
    "Z_test = X_test['text']\n",
    "# create a pipe instance \n",
    "pipe_cvec_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# decide on what parameters to modify for transformer and estimator\n",
    "params_cvec_rf = {\n",
    "    'cvec__stop_words': ['english'],\n",
    "    'cvec__ngram_range': [(1, 2)],\n",
    "    'cvec__max_df': [1.0, 0.8],\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__max_features': [1000, 3000],\n",
    "\n",
    "    'rf__n_estimators': [100, 150, 200],\n",
    "    'rf__max_depth': [None, 10, 100, 500],\n",
    "    'rf__random_state' : [42],\n",
    "    'rf__min_samples_split': [2, 8, 20],\n",
    "    'rf__min_samples_leaf': [1, 5, 10]\n",
    "\n",
    "}\n",
    "\n",
    "gs_cvec_rf = RandomizedSearchCV(pipe_cvec_rf,\n",
    "                 param_distributions=params_cvec_rf,\n",
    "                 n_jobs=-1,\n",
    "                 cv=3,\n",
    "                 n_iter=150,\n",
    "                 random_state=42,\n",
    "                 verbose=1)\n",
    "\n",
    "gs_cvec_rf.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= LogReg with text and numerical features =============\n",
      "best cv score: 0.843019680196802\n",
      "=============\n",
      "best params:\n",
      "rf__random_state: 42\n",
      "rf__n_estimators: 200\n",
      "rf__min_samples_split: 8\n",
      "rf__min_samples_leaf: 1\n",
      "rf__max_depth: None\n",
      "cvec__stop_words: english\n",
      "cvec__ngram_range: (1, 2)\n",
      "cvec__min_df: 2\n",
      "cvec__max_features: 3000\n",
      "cvec__max_df: 1.0\n",
      "=============\n",
      "train score: 0.9980781057810578\n",
      "test score: 0.839840147556102\n",
      "=============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_rf__random_state</th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>param_rf__min_samples_split</th>\n",
       "      <th>param_rf__min_samples_leaf</th>\n",
       "      <th>param_rf__max_depth</th>\n",
       "      <th>param_cvec__stop_words</th>\n",
       "      <th>...</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>109.685304</td>\n",
       "      <td>1.084800</td>\n",
       "      <td>4.953828</td>\n",
       "      <td>0.049119</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 2...</td>\n",
       "      <td>0.842712</td>\n",
       "      <td>0.848017</td>\n",
       "      <td>0.838330</td>\n",
       "      <td>0.843020</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>80.202850</td>\n",
       "      <td>2.515066</td>\n",
       "      <td>4.801436</td>\n",
       "      <td>0.112694</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 2...</td>\n",
       "      <td>0.842712</td>\n",
       "      <td>0.848017</td>\n",
       "      <td>0.838330</td>\n",
       "      <td>0.843020</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>61.789788</td>\n",
       "      <td>0.729063</td>\n",
       "      <td>4.742171</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>42</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 1...</td>\n",
       "      <td>0.839945</td>\n",
       "      <td>0.847325</td>\n",
       "      <td>0.839714</td>\n",
       "      <td>0.842328</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>63.562473</td>\n",
       "      <td>2.060702</td>\n",
       "      <td>4.720236</td>\n",
       "      <td>0.088202</td>\n",
       "      <td>42</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 1...</td>\n",
       "      <td>0.839945</td>\n",
       "      <td>0.847094</td>\n",
       "      <td>0.839022</td>\n",
       "      <td>0.842020</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>92.649003</td>\n",
       "      <td>2.624225</td>\n",
       "      <td>4.874978</td>\n",
       "      <td>0.079650</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 2...</td>\n",
       "      <td>0.838561</td>\n",
       "      <td>0.845710</td>\n",
       "      <td>0.841098</td>\n",
       "      <td>0.841790</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>59.334175</td>\n",
       "      <td>5.718600</td>\n",
       "      <td>5.265125</td>\n",
       "      <td>0.401963</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 1...</td>\n",
       "      <td>0.839483</td>\n",
       "      <td>0.848939</td>\n",
       "      <td>0.836255</td>\n",
       "      <td>0.841559</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>79.132396</td>\n",
       "      <td>3.328398</td>\n",
       "      <td>5.397956</td>\n",
       "      <td>0.621120</td>\n",
       "      <td>42</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 1...</td>\n",
       "      <td>0.838330</td>\n",
       "      <td>0.846633</td>\n",
       "      <td>0.839253</td>\n",
       "      <td>0.841405</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>75.601540</td>\n",
       "      <td>2.526679</td>\n",
       "      <td>5.226127</td>\n",
       "      <td>0.221122</td>\n",
       "      <td>42</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 2...</td>\n",
       "      <td>0.840637</td>\n",
       "      <td>0.842482</td>\n",
       "      <td>0.840406</td>\n",
       "      <td>0.841175</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>52.724481</td>\n",
       "      <td>1.523043</td>\n",
       "      <td>4.782631</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 1...</td>\n",
       "      <td>0.839483</td>\n",
       "      <td>0.847094</td>\n",
       "      <td>0.836255</td>\n",
       "      <td>0.840944</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72.875043</td>\n",
       "      <td>2.073955</td>\n",
       "      <td>4.612156</td>\n",
       "      <td>0.057167</td>\n",
       "      <td>42</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'rf__random_state': 42, 'rf__n_estimators': 1...</td>\n",
       "      <td>0.836946</td>\n",
       "      <td>0.847094</td>\n",
       "      <td>0.836716</td>\n",
       "      <td>0.840252</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "79      109.685304      1.084800         4.953828        0.049119   \n",
       "137      80.202850      2.515066         4.801436        0.112694   \n",
       "16       61.789788      0.729063         4.742171        0.026716   \n",
       "138      63.562473      2.060702         4.720236        0.088202   \n",
       "115      92.649003      2.624225         4.874978        0.079650   \n",
       "95       59.334175      5.718600         5.265125        0.401963   \n",
       "49       79.132396      3.328398         5.397956        0.621120   \n",
       "45       75.601540      2.526679         5.226127        0.221122   \n",
       "126      52.724481      1.523043         4.782631        0.123964   \n",
       "24       72.875043      2.073955         4.612156        0.057167   \n",
       "\n",
       "    param_rf__random_state param_rf__n_estimators param_rf__min_samples_split  \\\n",
       "79                      42                    200                           8   \n",
       "137                     42                    200                           8   \n",
       "16                      42                    150                           8   \n",
       "138                     42                    150                           8   \n",
       "115                     42                    200                           2   \n",
       "95                      42                    100                           2   \n",
       "49                      42                    150                           2   \n",
       "45                      42                    200                          20   \n",
       "126                     42                    100                           2   \n",
       "24                      42                    150                           2   \n",
       "\n",
       "    param_rf__min_samples_leaf param_rf__max_depth param_cvec__stop_words  \\\n",
       "79                           1                None                english   \n",
       "137                          1                 500                english   \n",
       "16                           1                 100                english   \n",
       "138                          1                 500                english   \n",
       "115                          1                None                english   \n",
       "95                           1                 100                english   \n",
       "49                           1                 100                english   \n",
       "45                           1                None                english   \n",
       "126                          1                None                english   \n",
       "24                           1                None                english   \n",
       "\n",
       "     ... param_cvec__min_df param_cvec__max_features param_cvec__max_df  \\\n",
       "79   ...                  2                     3000                1.0   \n",
       "137  ...                  2                     3000                1.0   \n",
       "16   ...                  2                     3000                0.8   \n",
       "138  ...                  2                     3000                0.8   \n",
       "115  ...                  2                     3000                1.0   \n",
       "95   ...                  2                     3000                0.8   \n",
       "49   ...                  2                     3000                0.8   \n",
       "45   ...                  2                     3000                1.0   \n",
       "126  ...                  2                     3000                1.0   \n",
       "24   ...                  2                     3000                0.8   \n",
       "\n",
       "                                                params split0_test_score  \\\n",
       "79   {'rf__random_state': 42, 'rf__n_estimators': 2...          0.842712   \n",
       "137  {'rf__random_state': 42, 'rf__n_estimators': 2...          0.842712   \n",
       "16   {'rf__random_state': 42, 'rf__n_estimators': 1...          0.839945   \n",
       "138  {'rf__random_state': 42, 'rf__n_estimators': 1...          0.839945   \n",
       "115  {'rf__random_state': 42, 'rf__n_estimators': 2...          0.838561   \n",
       "95   {'rf__random_state': 42, 'rf__n_estimators': 1...          0.839483   \n",
       "49   {'rf__random_state': 42, 'rf__n_estimators': 1...          0.838330   \n",
       "45   {'rf__random_state': 42, 'rf__n_estimators': 2...          0.840637   \n",
       "126  {'rf__random_state': 42, 'rf__n_estimators': 1...          0.839483   \n",
       "24   {'rf__random_state': 42, 'rf__n_estimators': 1...          0.836946   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "79            0.848017           0.838330         0.843020        0.003960   \n",
       "137           0.848017           0.838330         0.843020        0.003960   \n",
       "16            0.847325           0.839714         0.842328        0.003535   \n",
       "138           0.847094           0.839022         0.842020        0.003607   \n",
       "115           0.845710           0.841098         0.841790        0.002959   \n",
       "95            0.848939           0.836255         0.841559        0.005382   \n",
       "49            0.846633           0.839253         0.841405        0.003716   \n",
       "45            0.842482           0.840406         0.841175        0.000929   \n",
       "126           0.847094           0.836255         0.840944        0.004544   \n",
       "24            0.847094           0.836716         0.840252        0.004839   \n",
       "\n",
       "     rank_test_score  \n",
       "79                 1  \n",
       "137                1  \n",
       "16                 3  \n",
       "138                4  \n",
       "115                5  \n",
       "95                 6  \n",
       "49                 7  \n",
       "45                 8  \n",
       "126                9  \n",
       "24                10  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('============= LogReg with text and numerical features =============')\n",
    "print(f'best cv score: {gs_cvec_rf.best_score_}') # through cross-validation\n",
    "print('=============')\n",
    "print(f'best params:') # best parameters\n",
    "[print(f'{ind}: {val}') for ind, val in gs_cvec_rf.best_params_.items()];\n",
    "print('=============')\n",
    "pred = gs_cvec_rf.predict(Z_test)\n",
    "\n",
    "print(f'train score: {gs_cvec_rf.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs_cvec_rf.score(Z_test, y_test)}')\n",
    "\n",
    "print('=============')\n",
    "pd.DataFrame(gs_cvec_rf.cv_results_).sort_values(by='mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results, the performance of our ensemble based model is worse than the logistic regression and Naive Bayes. Also, although we have used ensemble of models, the random forest model shows almost a perfect fit to the training data while the test data does not show that much of a good results, which is an indication of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we investigated the performance of different estimators and transformers in classifying subreddits. Here are some of the key observations:\n",
    "- Logistic Regression and Naive Bayes models show similar performance while the latter runs faster, and both of them perform better than KNN classifier. \n",
    "- Using too many words (more than 3000 words) in classifying the documents seem not to help too much in our test score while contributing significantly to model variance and overfitting. \n",
    "- Both `TfidfVectorizer` and `CountVectorizer` provide similar performance with our estimators and there is no observer advantages over using any specific transformer. \n",
    "- There is no observed advantage of using extra information like sentiment scores and words counts for categorizing the listings from different subreddits.\n",
    "- Ensemble tree-based models like random forest tend to extremely overfit the data while the performance on the test data is not as good as logistic regression or Naive Bayes models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
