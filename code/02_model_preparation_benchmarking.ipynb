{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation and benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will:\n",
    "- Prepare the data based on observations from EDA\n",
    "- Null model prediction\n",
    "- Classifier without direct use of the words in the text (numeric features extracted from the text). Logistic regression is used as our estimator.\n",
    "- Simple classifier using NLP. Logistic regression and CountVectorizer were used as estimator and transformer in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import re \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # for sentiment analyzer\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from preprocessed data that are saved into files\n",
    "df = pd.read_csv('./../dataset/offmychestrelationship_advice_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.562143\n",
       "0    0.437857\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data does not have imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text', 'word_count', 'sentiment']]\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y)\n",
    "X_train = pd.DataFrame(X_train, columns=['text', 'word_count', 'sentiment'])\n",
    "X_test = pd.DataFrame(X_test, columns=['text', 'word_count', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3253, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.56225\n",
       "0    0.43775\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13008, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.562116\n",
       "0    0.437884\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.562116\n",
       "0    0.437884\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our null model is to predict all the subreddits as 1 (relationship_advice). This will give us an accuracy of 0.56. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to test the logistic regression model on the train data set by just using the numeric features we extracted from the data (number of words and sentiment scores). The purpose of this model will be to see if those information by themselves could do anything for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first scales the training data using standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "Z_train = sc.fit_transform(X_train[['word_count', 'sentiment']])\n",
    "Z_test = sc.transform(X_test[['word_count', 'sentiment']])\n",
    "\n",
    "logr = LogisticRegression()\n",
    "logr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data score: 0.64\n",
      "Test data score: 0.65\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data score: {round(logr.score(Z_train, y_train), 2)}')\n",
    "print(f'Test data score: {round(logr.score(Z_test, y_test), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results, with just using a simple linear regression and two numerical columns about the length of the text and the sentiment, we can get a 0.65 accuracy which is better than the null model. Note that since we are just using two features here, there is no need to regularize the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base NLP classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the base NLP model, we will just use logistic regression for our estimator and also CountVectorizer as our transformer and see how this model will perform. In next notebook, we will try other estimators and transformers to find the one with the best performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X train and test best on only the text column\n",
    "Z_train = X_train['text']\n",
    "Z_test = X_test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthwhile mentioning that the following cell has been run numerous times so that the best parameters are found and the search is limited to those, and we are only seeing the latest model here. In a real world with enough compute power, we may not need to do that but due to the computation power limitation in my personal laptop, I took a divide and conquer approach. Another approach to use here is RandomizedGridSearch which limits the number of samples but might miss some important points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "4 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1396, in fit_transform\n",
      "    X, self.stop_words_ = self._limit_features(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1245, in _limit_features\n",
      "    removed_terms.add(term)\n",
      "MemoryError\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1383, in fit_transform\n",
      "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1281, in _count_vocab\n",
      "    j_indices.extend(feature_counter.keys())\n",
      "MemoryError\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.87515375 0.87323186 0.8702337  0.86892681 0.86554428 0.87838253\n",
      " 0.87968942 0.87968942        nan        nan        nan 0.87138684\n",
      " 0.87092558 0.86938807 0.86400677 0.87799815 0.87922817 0.87930504\n",
      " 0.87845941 0.87538438 0.87553813 0.87069496 0.86931119 0.86846556\n",
      " 0.86400677 0.87838253 0.87968942 0.87968942 0.87961255 0.87692189\n",
      " 0.8753075  0.87054121 0.86954182 0.86846556 0.86331488 0.87799815\n",
      " 0.87922817 0.87930504 0.87845941 0.87538438 0.87476937 0.87092558\n",
      " 0.86754305 0.86662054 0.86146986 0.8775369  0.87984317 0.8803813\n",
      " 0.87984317 0.87684502 0.87476937 0.87107934 0.8676968  0.86662054\n",
      " 0.86131611 0.87769065 0.88030443 0.88030443 0.87999692 0.87707565]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;logr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [3000], &#x27;cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;logr__C&#x27;: [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;logr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [3000], &#x27;cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;logr__C&#x27;: [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()), (&#x27;logr&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('logr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [1.0, 0.8, 0.5],\n",
       "                         'cvec__max_features': [3000], 'cvec__min_df': [2, 4],\n",
       "                         'cvec__ngram_range': [(1, 2)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'logr__C': [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         'logr__penalty': ['l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pipe instance \n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# decide on what parameters to modify for transformer and estimator\n",
    "pipe_params = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "#   'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],    \n",
    "    'cvec__ngram_range': [(1, 2)],\n",
    "    'cvec__max_df': [1.0, 0.8, 0.5],\n",
    "    'cvec__min_df': [2, 4],\n",
    "#   'cvec__max_features': [500, 1000, 3000, 5000],\n",
    "    'cvec__max_features': [3000],\n",
    "\n",
    "    'logr__C': [0.02, 0.05, 0.07, 0.1, 0.2],\n",
    "    'logr__penalty': ['l2'], #, 'elasticnet', 'none']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs=-1,\n",
    "                 cv=3,\n",
    "                 verbose=3)\n",
    "\n",
    "gs.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.8803813038130381\n",
      "best params: {'cvec__max_df': 0.5, 'cvec__max_features': 3000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english', 'logr__C': 0.07, 'logr__penalty': 'l2'}\n",
      "=============\n",
      "train score: 0.9491851168511685\n",
      "test score: 0.8834921610820781\n",
      "=============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>param_cvec__stop_words</th>\n",
       "      <th>param_logr__C</th>\n",
       "      <th>param_logr__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>21.233511</td>\n",
       "      <td>0.252291</td>\n",
       "      <td>6.636843</td>\n",
       "      <td>0.227249</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.07</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 30...</td>\n",
       "      <td>0.882611</td>\n",
       "      <td>0.880304</td>\n",
       "      <td>0.878229</td>\n",
       "      <td>0.880381</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>21.384796</td>\n",
       "      <td>0.364946</td>\n",
       "      <td>6.427360</td>\n",
       "      <td>0.414535</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.07</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 30...</td>\n",
       "      <td>0.883072</td>\n",
       "      <td>0.880074</td>\n",
       "      <td>0.877768</td>\n",
       "      <td>0.880304</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>21.644410</td>\n",
       "      <td>0.194813</td>\n",
       "      <td>6.025435</td>\n",
       "      <td>0.285132</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.05</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 30...</td>\n",
       "      <td>0.881227</td>\n",
       "      <td>0.882149</td>\n",
       "      <td>0.877537</td>\n",
       "      <td>0.880304</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>20.376885</td>\n",
       "      <td>0.334262</td>\n",
       "      <td>5.595811</td>\n",
       "      <td>0.988325</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 30...</td>\n",
       "      <td>0.883994</td>\n",
       "      <td>0.878921</td>\n",
       "      <td>0.877076</td>\n",
       "      <td>0.879997</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>21.558097</td>\n",
       "      <td>0.686077</td>\n",
       "      <td>6.219707</td>\n",
       "      <td>0.223955</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.05</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 30...</td>\n",
       "      <td>0.880535</td>\n",
       "      <td>0.881458</td>\n",
       "      <td>0.877537</td>\n",
       "      <td>0.879843</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "47      21.233511      0.252291         6.636843        0.227249   \n",
       "57      21.384796      0.364946         6.427360        0.414535   \n",
       "56      21.644410      0.194813         6.025435        0.285132   \n",
       "58      20.376885      0.334262         5.595811        0.988325   \n",
       "46      21.558097      0.686077         6.219707        0.223955   \n",
       "\n",
       "   param_cvec__max_df param_cvec__max_features param_cvec__min_df  \\\n",
       "47                0.5                     3000                  2   \n",
       "57                0.5                     3000                  4   \n",
       "56                0.5                     3000                  4   \n",
       "58                0.5                     3000                  4   \n",
       "46                0.5                     3000                  2   \n",
       "\n",
       "   param_cvec__ngram_range param_cvec__stop_words param_logr__C  \\\n",
       "47                  (1, 2)                english          0.07   \n",
       "57                  (1, 2)                english          0.07   \n",
       "56                  (1, 2)                english          0.05   \n",
       "58                  (1, 2)                english           0.1   \n",
       "46                  (1, 2)                english          0.05   \n",
       "\n",
       "   param_logr__penalty                                             params  \\\n",
       "47                  l2  {'cvec__max_df': 0.5, 'cvec__max_features': 30...   \n",
       "57                  l2  {'cvec__max_df': 0.5, 'cvec__max_features': 30...   \n",
       "56                  l2  {'cvec__max_df': 0.5, 'cvec__max_features': 30...   \n",
       "58                  l2  {'cvec__max_df': 0.5, 'cvec__max_features': 30...   \n",
       "46                  l2  {'cvec__max_df': 0.5, 'cvec__max_features': 30...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "47           0.882611           0.880304           0.878229         0.880381   \n",
       "57           0.883072           0.880074           0.877768         0.880304   \n",
       "56           0.881227           0.882149           0.877537         0.880304   \n",
       "58           0.883994           0.878921           0.877076         0.879997   \n",
       "46           0.880535           0.881458           0.877537         0.879843   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "47        0.001790                1  \n",
       "57        0.002172                2  \n",
       "56        0.001993                2  \n",
       "58        0.002925                4  \n",
       "46        0.001674                5  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'best score: {gs.best_score_}') # through cross-validation\n",
    "print(f'best params: {gs.best_params_}') # best parameters\n",
    "print('=============')\n",
    "pred = gs.predict(Z_test)\n",
    "\n",
    "print(f'train score: {gs.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs.score(Z_test, y_test)}')\n",
    "\n",
    "print('=============')\n",
    "pd.DataFrame(gs.cv_results_).sort_values(by='mean_test_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us take a look at the predictions and see what is the specificity and sensitivity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity (true negatives/actual negatives): 0.87\n",
      "sensitivity (recall) (true positives/actual positives): 0.89\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f'specificity (true negatives/actual negatives): {round(tn/(tn+fp), 2)}')\n",
    "print(f'sensitivity (recall) (true positives/actual positives): {round(tp/(tp+fn), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model performs similarly for the negative and positive class. Part of this behavior is because the data we have used in this section is relatively balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key takeaways\n",
    "\n",
    "During the benchmarking process, we used logistic regression and countvectorizer to convert the text into numbers and see how that could be used for training the model on the train data and test it on the test data. Here are a few conclusions after multiple rounds of modeling and parameter tuning:\n",
    "- Some of the common parameters for countvectorizer and logistic regression was used and the best performance showed and accuracy of about 0.87, which was better than the null model and also the model with simple features. \n",
    "- We used regularization as a way to overcome overfitting and it was successful to some extent, but the final model still suffers from overfitting. l1 regularization was way more aggressive than l2 in limiting model variance but they both achieved similar results. l2 regularization was used because of it's flexibility in using the solver and faster response. \n",
    "- Various hyperparameter tuning schemes were used to limit model variance by making the model performance on training and test (or crossvalidate) data comparable while at the same time improving the test/crossval scores of the model. However, the test/crossval score did not got more than 0.88 in any of the models. \n",
    "- Looking at the ``cv_results_`` of the latest and greatest search, we can see that almost all of the combination of the parameters in the GridSearchCV result in a similar score. This makes us think the current model will not show any more improvement in the results in case we just focus on the current hyperparameters to optimize and in fact, the best performance of the model has already reached. <br>\n",
    "\n",
    "**Some notes on overfitting**\n",
    "- As part of the effort to investigate how the model performs, we focused on the ``max_features`` parameter and increased this feature from 500 to 7000 and also no limit.\n",
    "- Our observation shows that for smaller ``max_features`` the train score and test/cv scores are low (train score of 87 and cv score of 84 when a maximum of 500 features are used).\n",
    "- As the ``max_features`` number increased (3000), the train scored increased rapidly but the cv score increased slowly and reached a plateau of 0.87. Further increase in the in the maximum number of features caused the train score goes up to 0.99 while the test/cv score did not improved after 0.87. \n",
    "- One conclusion we can draw out of this discussion is the fact that the reason for the observed overfitting is that we are using too many features while using these number of features improves the training score and does not help with the test/cv score. \n",
    "- In other words, if we use a maximum of 2000 words, train score (0.91) becomes very close to the test/cv score of (0.86) without sacrificing the performance of the model, and the model does not seem to be overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
