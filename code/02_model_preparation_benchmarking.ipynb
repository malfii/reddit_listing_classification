{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation and benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will:\n",
    "- Prepare the data based on observations from EDA\n",
    "- Null model prediction\n",
    "- Classifier without direct use of the words in the text (numeric features extracted from the text). Logistic regression is used as our estimator.\n",
    "- Simple classifier using NLP. Logistic regression and CountVectorizer were used as estimator and transformer in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import re \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # for sentiment analyzer\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on observations from the EDA part, we will prepare a dataframe to use for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>listingid</th>\n",
       "      <th>created</th>\n",
       "      <th>url</th>\n",
       "      <th>media</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I had a few toxic relationships as a teenage a...</td>\n",
       "      <td>I'm more than I ever expected to be</td>\n",
       "      <td>18n8wrf</td>\n",
       "      <td>1.703116e+09</td>\n",
       "      <td>https://www.reddit.com/r/offmychest/comments/1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offmychest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TLDR is, essentially, the title.\\n\\nFor a litt...</td>\n",
       "      <td>How do I (F27) ask my BF (M27) to be less jeal...</td>\n",
       "      <td>18naxqe</td>\n",
       "      <td>1.703122e+09</td>\n",
       "      <td>https://www.reddit.com/r/relationship_advice/c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relationship_advice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I had a few toxic relationships as a teenage a...   \n",
       "1  TLDR is, essentially, the title.\\n\\nFor a litt...   \n",
       "\n",
       "                                               title listingid       created  \\\n",
       "0                I'm more than I ever expected to be   18n8wrf  1.703116e+09   \n",
       "1  How do I (F27) ask my BF (M27) to be less jeal...   18naxqe  1.703122e+09   \n",
       "\n",
       "                                                 url  media  \\\n",
       "0  https://www.reddit.com/r/offmychest/comments/1...    NaN   \n",
       "1  https://www.reddit.com/r/relationship_advice/c...    NaN   \n",
       "\n",
       "             subreddit  \n",
       "0           offmychest  \n",
       "1  relationship_advice  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data from the .csv file created in the previous section\n",
    "df = pd.read_csv('./../dataset/offmychestrelationship_advice.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I had a few toxic relationships as a teenage a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TLDR is, essentially, the title.\\n\\nFor a litt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\r  \\nAnd probably not in the way you think.\\r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  subreddit\n",
       "0  I had a few toxic relationships as a teenage a...          0\n",
       "1  TLDR is, essentially, the title.\\n\\nFor a litt...          1\n",
       "2  \\r  \\nAnd probably not in the way you think.\\r...          0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "df = df.drop(columns=['listingid', 'created', 'url', 'media'])\n",
    "# mix text and title columns\n",
    "df['text'] = df.apply(lambda x: x['text'] + x['title'], axis=1)\n",
    "df = df.drop(columns=['title'])\n",
    "# convert subreddit names to numbers offmychest = 0, relationship_advice = 1\n",
    "df['subreddit'] = df['subreddit'].map({'offmychest': 0, 'relationship_advice': 1})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column for the word count in the text\n",
    "df['word_count'] = df['text'].apply(lambda x: len(re.findall(r'(?u)\\b\\w\\w+\\b', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I had a few toxic relationships as a teenage a...</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>0.9515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TLDR is, essentially, the title.\\n\\nFor a litt...</td>\n",
       "      <td>1</td>\n",
       "      <td>494</td>\n",
       "      <td>0.8858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\r  \\nAnd probably not in the way you think.\\r...</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>0.8559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  subreddit  word_count  \\\n",
       "0  I had a few toxic relationships as a teenage a...          0         186   \n",
       "1  TLDR is, essentially, the title.\\n\\nFor a litt...          1         494   \n",
       "2  \\r  \\nAnd probably not in the way you think.\\r...          0         190   \n",
       "\n",
       "   sentiment  \n",
       "0     0.9515  \n",
       "1     0.8858  \n",
       "2     0.8559  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new column for the sentiment of the text in each listing\n",
    "sent = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df.apply(lambda x: \n",
    "                           sent.polarity_scores(x['text'])['compound'],\n",
    "                           axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.561612\n",
       "0    0.438388\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data does not have imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text', 'word_count', 'sentiment']]\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y)\n",
    "X_train = pd.DataFrame(X_train, columns=['text', 'word_count', 'sentiment'])\n",
    "X_test = pd.DataFrame(X_test, columns=['text', 'word_count', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2041, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.561489\n",
       "0    0.438511\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8160, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.561642\n",
       "0    0.438358\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.561642\n",
       "0    0.438358\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our null model is to predict all the subreddits as 1 (relationship_advice). This will give us an accuracy of 0.54. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to test the logistic regression model on the train data set by just using the numeric features we extracted from the data (number of words and sentiment scores). The purpose of this model will be to see if those information by themselves could do anything for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first scales the training data using standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "Z_train = sc.fit_transform(X_train[['word_count', 'sentiment']])\n",
    "Z_test = sc.transform(X_test[['word_count', 'sentiment']])\n",
    "\n",
    "logr = LogisticRegression()\n",
    "logr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data score: 0.64\n",
      "Test data score: 0.61\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data score: {round(logr.score(Z_train, y_train), 2)}')\n",
    "print(f'Test data score: {round(logr.score(Z_test, y_test), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results, with just using a simple linear regression and two numerical columns about the length of the text and the sentiment, we can get a 0.61 accuracy which is better than the null model. Note that since we are just using two features here, there is no need to regularize the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base NLP classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the base NLP model, we will just use logistic regression for our estimator and also CountVectorizer as our transformer and see how this model will perform. In next notebook, we will try other estimators and transformers to find the one with the best performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X train and test best on only the text column\n",
    "Z_train = X_train['text']\n",
    "Z_test = X_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\masou\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;logr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [3000], &#x27;cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;logr__C&#x27;: [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;logr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.8, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [3000], &#x27;cvec__min_df&#x27;: [2, 4],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;logr__C&#x27;: [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()), (&#x27;logr&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('logr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [1.0, 0.8, 0.5],\n",
       "                         'cvec__max_features': [3000], 'cvec__min_df': [2, 4],\n",
       "                         'cvec__ngram_range': [(1, 2)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'logr__C': [0.02, 0.05, 0.07, 0.1, 0.2],\n",
       "                         'logr__penalty': ['l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pipe instance \n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# decide on what parameters to modify for transformer and estimator\n",
    "pipe_params = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__ngram_range': [(1, 2)],\n",
    "    'cvec__max_df': [1.0, 0.8, 0.5],\n",
    "    'cvec__min_df': [2, 4],\n",
    "#   'cvec__max_features': [500, 1000, 3000, 5000],\n",
    "    'cvec__max_features': [3000],\n",
    "\n",
    "    'logr__C': [0.02, 0.05, 0.07, 0.1, 0.2],\n",
    "    'logr__penalty': ['l2'], #, 'elasticnet', 'none']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs=-1,\n",
    "                 cv=3,\n",
    "                 verbose=3)\n",
    "\n",
    "gs.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.8703431372549021\n",
      "best params: {'cvec__max_df': 1.0, 'cvec__max_features': 3000, 'cvec__min_df': 4, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english', 'logr__C': 0.07, 'logr__penalty': 'l2'}\n",
      "=============\n",
      "train score: 0.9609068627450981\n",
      "test score: 0.8682018618324351\n",
      "=============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>param_cvec__stop_words</th>\n",
       "      <th>param_logr__C</th>\n",
       "      <th>param_logr__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14.346957</td>\n",
       "      <td>0.090426</td>\n",
       "      <td>3.768180</td>\n",
       "      <td>0.031670</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.07</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 0.8, 'cvec__max_features': 30...</td>\n",
       "      <td>0.875735</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.870343</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.105523</td>\n",
       "      <td>0.220617</td>\n",
       "      <td>2.691191</td>\n",
       "      <td>0.031231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.07</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 1.0, 'cvec__max_features': 30...</td>\n",
       "      <td>0.875735</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.870343</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.422559</td>\n",
       "      <td>0.241344</td>\n",
       "      <td>2.803794</td>\n",
       "      <td>0.050545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.07</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 1.0, 'cvec__max_features': 30...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.870098</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.428231</td>\n",
       "      <td>0.746700</td>\n",
       "      <td>3.362933</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.07</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 0.8, 'cvec__max_features': 30...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.870098</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11.452624</td>\n",
       "      <td>0.446889</td>\n",
       "      <td>3.419002</td>\n",
       "      <td>0.189244</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.05</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'cvec__max_df': 0.8, 'cvec__max_features': 30...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871691</td>\n",
       "      <td>0.860662</td>\n",
       "      <td>0.869118</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "37      14.346957      0.090426         3.768180        0.031670   \n",
       "17       9.105523      0.220617         2.691191        0.031231   \n",
       "7        9.422559      0.241344         2.803794        0.050545   \n",
       "27      12.428231      0.746700         3.362933        0.026647   \n",
       "26      11.452624      0.446889         3.419002        0.189244   \n",
       "\n",
       "   param_cvec__max_df param_cvec__max_features param_cvec__min_df  \\\n",
       "37                0.8                     3000                  4   \n",
       "17                1.0                     3000                  4   \n",
       "7                 1.0                     3000                  2   \n",
       "27                0.8                     3000                  2   \n",
       "26                0.8                     3000                  2   \n",
       "\n",
       "   param_cvec__ngram_range param_cvec__stop_words param_logr__C  \\\n",
       "37                  (1, 2)                english          0.07   \n",
       "17                  (1, 2)                english          0.07   \n",
       "7                   (1, 2)                english          0.07   \n",
       "27                  (1, 2)                english          0.07   \n",
       "26                  (1, 2)                english          0.05   \n",
       "\n",
       "   param_logr__penalty                                             params  \\\n",
       "37                  l2  {'cvec__max_df': 0.8, 'cvec__max_features': 30...   \n",
       "17                  l2  {'cvec__max_df': 1.0, 'cvec__max_features': 30...   \n",
       "7                   l2  {'cvec__max_df': 1.0, 'cvec__max_features': 30...   \n",
       "27                  l2  {'cvec__max_df': 0.8, 'cvec__max_features': 30...   \n",
       "26                  l2  {'cvec__max_df': 0.8, 'cvec__max_features': 30...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "37           0.875735           0.870588           0.864706         0.870343   \n",
       "17           0.875735           0.870588           0.864706         0.870343   \n",
       "7            0.875000           0.870588           0.864706         0.870098   \n",
       "27           0.875000           0.870588           0.864706         0.870098   \n",
       "26           0.875000           0.871691           0.860662         0.869118   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "37        0.004506                1  \n",
       "17        0.004506                1  \n",
       "7         0.004217                3  \n",
       "27        0.004217                3  \n",
       "26        0.006130                5  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'best score: {gs.best_score_}') # through cross-validation\n",
    "print(f'best params: {gs.best_params_}') # best parameters\n",
    "print('=============')\n",
    "pred = gs.predict(Z_test)\n",
    "\n",
    "print(f'train score: {gs.score(Z_train, y_train)}')\n",
    "print(f'test score: {gs.score(Z_test, y_test)}')\n",
    "\n",
    "print('=============')\n",
    "pd.DataFrame(gs.cv_results_).sort_values(by='mean_test_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the benchmarking process, we used logistic regression and countvectorizer to convert the text into numbers and see how that could be used for training the model on the train data and test it on the test data. Here are a few conclusions after multiple rounds of modeling and parameter tuning:\n",
    "- Some of the common parameters for countvectorizer and logistic regression was used and the best performance showed and accuracy of about 0.87, which was better than the null model and also the model with simple features. \n",
    "- We used regularization as a way to overcome overfitting and it was successful to some extent, but the final model still suffers from overfitting. l1 regularization was way more aggressive than l2 in limiting model variance but they both achieved similar results. l2 regularization was used because of it's flexibility in using the solver and faster response. \n",
    "- Various hyperparameter tuning schemes were used to limit model variance by making the model performance on training and test (or crossvalidate) data comparable while at the same time improving the test/crossval scores of the model. However, the test/crossval score did not got more than 0.88 in any of the models. \n",
    "- In an effort to decrease the variance and improve model performance, we bumped up the number of listing data from 7000 to 10000 but model performance did not show any improvement. \n",
    "- Looking at the ``cv_results_``, we can see that almost all of the combination of the parameters in the GridSearchCV result in a similar score. This makes us think the current model will not show any more improvement in the results in case we just focus on the current hyperparameters to optimize and in fact, the best performance of the model has already reached. <br>\n",
    "\n",
    "**Some notes on overfitting**\n",
    "- As part of the effort to investigate how the model performs, we focused on the ``max_features`` parameter and increased this feature from 500 to 7000 and also no limit.\n",
    "- Our observation shows that for smaller ``max_features`` the train score and test/cv scores are low (train score of 87 and cv score of 84 when a maximum of 500 features are used).\n",
    "- As the ``max_features`` number increased (3000), the train scored increased rapidly but the cv score increased slowly and reached a plateau of 0.87. Further increase in the in the maximum number of features caused the train score goes up to 0.99 while the test/cv score did not improved after 0.87. \n",
    "- One conclusion we can draw out of this discussion is the fact that the reason for the observed overfitting is that we are using too many features while using these number of features improves the training score and does not help with the test/cv score. \n",
    "- In other words, if we use a maximum of 2000 words, train score (0.91) becomes very close to the test/cv score of (0.86) without sacrificing the performance of the model, and the model does not seem to be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us take a look at the predictions and see what is the specificity and sensitivity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity (true negatives/actual negatives): 0.86\n",
      "sensitivity/recall (true positives/actual positives): 0.87\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f'specificity (true negatives/actual negatives): {round(tn/(tn+fp), 2)}')\n",
    "print(f'sensitivity/recall (true positives/actual positives): {round(tp/(tp+fn), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model performs similarly for the negative and positive class. Part of this behavior is because the data we have used in this section is relatively balanced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
